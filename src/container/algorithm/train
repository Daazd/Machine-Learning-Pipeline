import os
import json
import pickle
import sys
import traceback
import logging
import time


import pandas as pd
from sklearn import tree
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score, KFold, GridSearchCV
from numpy import mean, std 

# These are the paths to where SageMaker mounts interesting things in your container.

prefix = '/opt/ml/'

input_path = prefix + 'input/data'
output_path = os.path.join(prefix, 'output')
model_path = os.path.join(prefix, 'model')
param_path = os.path.join(prefix, 'input/config/hyperparameters.json')

# This algorithm has a single channel of input data called 'training'. Since we run in
# File mode, the input files are copied to the directory specified here.
channel_name='training'
training_path = os.path.join(input_path, channel_name)
logging.basicConfig(level=logging.INFO)

# The function to execute the training.
def train():
    logging.info('Starting the training.')
    try:
        # Read in any hyperparameters that the user passed with the training job
        with open(param_path, 'r') as tc:
            trainingParams = json.load(tc)

        # Take the set of files and read them all into a single pandas dataframe
        input_files = [ os.path.join(training_path, file) for file in os.listdir(training_path) ]
        if len(input_files) == 0:
            raise ValueError(('There are no files in {}.\n' +
                              'This usually indicates that the channel ({}) was incorrectly specified,\n' +
                              'the data specification in S3 was incorrectly specified or the role specified\n' +
                              'does not have permission to access the data.').format(training_path, channel_name))
        logging.info('Loading dataset')
        # This needs to be modified based on the input file format
        # raw_data = [ pd.read_json(file) for file in input_files ]
        raw_data = [ pd.read_csv(file, header=None) for file in input_files ]
        train_data = pd.concat(raw_data)

        # labels are in the first column
        logging.info('Splitting into features and labels')
        train_y = train_data.loc[:,0]
        train_X = train_data.loc[:,1:]

        # Preprocessing Data
        scaler = StandardScaler()
        train_X = scaler.fit_transform(train_X)

        # Defining the Hyperparameter grid for Random Forest
        param_grid = {
            'n_estimators': trainingParams.get('n_estimators', [50, 100, 150]),
            'max_depth': trainingParams.get('max_depth', [None, 10, 20, 30])
        }
        
        clf = RandomForestClassifier()

        # Defining the grid search
        grid_search = GridSearchCV(estimator=clf, param_grid=param_grid, n_jobs=-1, cv=5)
        logging.info('Training the model')
        grid_search.fit(train_X, train_y)
        
        # Report the best parameters
        logging.info('Best parameters: {}'.format(grid_search.best_params_))
        
        # Output the best model
        clf = grid_search.best_estimator_
        
        # Evaluate the model and Cross-Validation
        cv = KFold(n_splits=10, random_state=1, shuffle=True)
        n_scores = cross_val_score(clf, train_X, train_y, scoring='accuracy', cv=cv, n_jobs=-1)

        # Report the model performance
        logging.info('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))

        # Save the model
        logging.info('Saving the model')
        with open(os.path.join(model_path, 'default-model.pkl'), 'wb') as out:
            pickle.dump(clf, out)
        logging.info('Training complete.')
    except Exception as e:
        # Write out an error file. This will be returned as the failureReason in the
        # DescribeTrainingJob result.
        trc = traceback.format_exc()
        with open(os.path.join(output_path, 'failure'), 'w') as s:
            s.write('Exception during training: ' + str(e) + '\n' + trc)
        #   logging.infoing this causes the exception to be in the training job logs, as well.
        logging.info('Exception during training: ' + str(e) + '\n' + trc, file=sys.stderr)
        # A non-zero exit code causes the training job to be marked as Failed.
        sys.exit(255)

if __name__ == '__main__':
    train()

    # A zero exit code causes the job to be marked as succeeded.
    sys.exit(0)
